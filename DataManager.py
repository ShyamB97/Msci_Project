# -*- coding: utf-8 -*-
"""
Created on Mon Feb  3 12:24:13 2020

@author: bhull
"""

import uproot
from natsort import natsorted, ns
import numpy as np
import os
import pandas as pd

"""Will reuturn the root filenames in a given directory"""
def GetFileNames(directory='\samples'):
    eventFiles = []
    path = os.getcwd() + directory
    for root, dirs, files in os.walk(path):
        for file in files:
            if file.endswith(".root"):
                path_file = os.path.join(directory[1:],file)
                #print(path_file)
                eventFiles.append(path_file)
    return eventFiles


"""Opens ROOT file generated by MINT and stores particle data into a dictionary"""
def MINTdf(filename='GeneratedMC_1.root', CP=False):
    tree = uproot.open('GeneratedMC_1.root')['DalitzEventList']
    df = tree.pandas.df()
    df_n = np.array(df)

    if CP is True:
        mask = [[1, -1, -1, -1]] * np.size(df, 0)
    if CP is False:
        mask = [[1, 1, 1, 1]] * np.size(df, 0)
    mask = np.array(mask)

    """data for each particles (MeV) where a row is a 4 vector"""
    p_0 = df_n[:, 1:5] * mask
    p_1 = df_n[:, 6:10] * mask
    p_2 = df_n[:, 11:15] * mask
    p_3 = df_n[:, 16:20] * mask  # may not be normally distributed
    p_4 = df_n[:, 21:25] * mask  # may not be normally distributed
    particles = {'p_0': p_0, 'p_1': p_1, 'p_2': p_2, 'p_3': p_3, 'p_4': p_4}
    return particles


"""Opens ROOT file generated by AmpGen and stores particle data into a dictionary"""
def AmpGendf(filename='output.root', CP=False):
    tree = uproot.open(filename)['DalitzEventList']
    df = tree.pandas.df()
    df_n = np.array(df) * 1000  # GeV to MeV
    df_n = df_n[:, 0:16]

    if CP is True:
        mask = [[1, -1, -1, -1]] * np.size(df, 0)
    if CP is False:
        mask = [[1, 1, 1, 1]] * np.size(df, 0)
    mask = np.array(mask)

    p_1 = df_n[:, 0:4] * mask
    p_2 = df_n[:, 4:8] * mask
    p_3 = df_n[:, 8:12] * mask
    p_4 = df_n[:, 12:16] * mask
    p_0 = p_1 + p_2 + p_3 + p_4
    particles = {'p_0': p_0, 'p_1': p_1, 'p_2': p_2, 'p_3': p_3, 'p_4': p_4}
    return particles


"""If a eventfile is too large to interpret, this will split the data set into smaller ones"""
def SplitEvents(particles, number=10):
    events = np.size(particles['p_0'], 0)
    segments= int(events/number)
    p = []

    for i in particles:
        particle = particles[i]
        for j in range(number):
            p.append(particle[j*segments: segments*(j+1), :])

    data = []
    for i in range(number):
        p_0 = p[0 + i]
        p_1 = p[1*number + i]
        p_2 = p[2*number + i]
        p_3 = p[3*number + i]
        p_4 = p[4*number + i]
        subset = {'p_0': p_0, 'p_1': p_1, 'p_2': p_2, 'p_3': p_3, 'p_4': p_4}
        data.append(subset)
    return data


"""Get mutiple dataframes in a list from a directory"""
def GenerateDataFrames(directory, CP):
    fileNames = GetFileNames(directory)
    fileNames = natsorted(fileNames, alg=ns.IGNORECASE)  # sorted by amplitudes

    """Produce dataframes for each file"""
    data = []
    for i in range(len(fileNames)):
        p = AmpGendf(fileNames[i], CP)
        data.append(p)
    return data


"""Merges dataframes into a single list of values (preserves order)"""
def MergeData(lst, dfs=10):
    data_full = []
    for i in range(5):
        particle = []
        name = 'p_' + str(i)
        for j in range(dfs):
            particle.append(lst[j][name])
        data_full.append(np.vstack(particle))
    return data_full


"""Used to construct numpy 4-Vectors from the real data set. Splits into regular and conjugate decays"""
def ConstructParticle(particleName, df, tags):
    component_name = ['_PE', '_PX', '_PY', '_PZ']
    component = []
    for i in range(len(component_name)):
        component.append(df[particleName + component_name[i]].to_numpy())
    component = np.vstack(component).T
    p = component[tags > 0]
    pbar = component[tags < 0]
    return p, pbar


"""Reads the Real Data (stored in a pickle file) and returns particles dictionary and the signal weightings"""
def ReadRealData():
    df = pd.read_pickle('Data_sig_tos_weights.pkl')
    opt_cut = 0.9979
    df = df[df.NN_weights > opt_cut]
    ### to remove multiple candidates if you care â€“ there are about 1-2% of these
    df = df.drop_duplicates(subset = ['runNumber', 'eventNumber'], keep = 'first')
    
    sWeights = df.sWeights.to_numpy()
    Ktags = df["K_Kst0_ID"].to_numpy()

    p_0 = ConstructParticle('B0', df, Ktags)
    p_1 = ConstructParticle('D0', df, Ktags)
    p_2 = ConstructParticle('D0bar', df, Ktags)
    p_3 = ConstructParticle('K_Kst0', df, Ktags)
    p_4 = ConstructParticle('Pi_Kst0', df, Ktags)
    
    particles = {'p_0': p_0[0], 'p_1': p_1[0], 'p_2': p_2[0], 'p_3': p_3[0], 'p_4': p_4[0]}
    particlesbar = {'p_0': p_0[1], 'p_1': p_1[1], 'p_2': p_2[1], 'p_3': p_3[1], 'p_4': p_4[1]}
    
    weights = sWeights[Ktags > 0]
    weightsbar = sWeights[Ktags < 0]
    return particles, particlesbar, weights, weightsbar
