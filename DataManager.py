# -*- coding: utf-8 -*-
"""
Created on Mon Feb  3 12:24:13 2020

@author: bhull
"""

import uproot
import numpy as np
import os

"""Will reuturn the root filenames in a given directory"""
def GetFileNames(directory='\samples'):
    eventFiles = []
    path = os.getcwd() + directory
    for root, dirs, files in os.walk(path):
        for file in files:
            if file.endswith(".root"):
                path_file = os.path.join(directory[1:],file)
                #print(path_file)
                eventFiles.append(path_file)
    return eventFiles


"""Opens ROOT file generated by MINT and stores particle data into a dictionary"""
def MINTdf(filename='GeneratedMC_1.root', CP=False):
    tree = uproot.open('GeneratedMC_1.root')['DalitzEventList']
    df = tree.pandas.df()
    df_n = np.array(df)

    if CP is True:
        mask = [[1, -1, -1, -1]] * np.size(df, 0)
    if CP is False:
        mask = [[1, 1, 1, 1]] * np.size(df, 0)
    mask = np.array(mask)

    """data for each particles (MeV) where a row is a 4 vector"""
    p_0 = df_n[:, 1:5] * mask
    p_1 = df_n[:, 6:10] * mask
    p_2 = df_n[:, 11:15] * mask
    p_3 = df_n[:, 16:20] * mask  # may not be normally distributed
    p_4 = df_n[:, 21:25] * mask  # may not be normally distributed
    particles = {'p_0': p_0, 'p_1': p_1, 'p_2': p_2, 'p_3': p_3, 'p_4': p_4}
    return particles


"""Opens ROOT file generated by AmpGen and stores particle data into a dictionary"""
def AmpGendf(filename='output.root', CP=False):
    tree = uproot.open(filename)['DalitzEventList']
    df = tree.pandas.df()
    df_n = np.array(df) * 1000  # GeV to MeV
    df_n = df_n[:, 0:16]

    if CP is True:
        mask = [[1, -1, -1, -1]] * np.size(df, 0)
    if CP is False:
        mask = [[1, 1, 1, 1]] * np.size(df, 0)
    mask = np.array(mask)

    p_1 = df_n[:, 0:4] * mask
    p_2 = df_n[:, 4:8] * mask
    p_3 = df_n[:, 8:12] * mask
    p_4 = df_n[:, 12:16] * mask
    p_0 = p_1 + p_2 + p_3 + p_4
    particles = {'p_0': p_0, 'p_1': p_1, 'p_2': p_2, 'p_3': p_3, 'p_4': p_4}
    return particles


"""If a eventfile is too large to interpret, this will split the data set into smaller ones"""
def SplitEvents(particles, number = 10):
    events = np.size(particles['p_0'], 0)
    segments= int(events/number)
    p = []

    for i in particles:
        particle = particles[i]
        for j in range(number):
            p.append(particle[j*segments: segments*(j+1), :])

    data = []
    for i in range(number):
        p_0 = p[0 + i]
        p_1 = p[10 + i]
        p_2 = p[20 + i]
        p_3 = p[30 + i]
        p_4 = p[40 + i]
        subset = {'p_0': p_0, 'p_1': p_1, 'p_2': p_2, 'p_3': p_3, 'p_4': p_4}
        data.append(subset)
    return data















